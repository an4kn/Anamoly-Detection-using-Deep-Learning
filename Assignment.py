# -*- coding: utf-8 -*-
"""Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P4Dq0bzBhq4EkQUqHR3olLphRmfa9ofX
"""
#installing the "pyod" library in colab environment
!pip install -q pyod

#importing libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pyod

#importing the csv file
df = pd.read_csv('/content/drive/My Drive/baldwin_pump_data.csv')
df = df.rename(columns = {'Unnamed: 0':'TIMESTAMP'})
print(list(df.columns))

#filling the NaN values in the dataset
print(df.isnull().values.sum())
df = df.fillna(method = 'ffill')
df = df.fillna(method = 'bfill')
print(df.isnull().values.sum())

#plotting the speed input to determine the threshold for shutdown
print(df['BFPT_B_LP_SPEED_INPUT__1__'].describe())
plt.figure(figsize = [30,10])
columns = ['BFPT_B_LP_SPEED_INPUT__1__']
X = df[columns]
plt.plot(X)
ax = plt.gca()
ax.axes.xaxis.set_visible(False)
plt.legend(columns)
plt.show()

#classifying between running state and shutdown stage
shut = df[df['BFPT_B_LP_SPEED_INPUT__1__'] < 4500]
on = df[df['BFPT_B_LP_SPEED_INPUT__1__'] >= 4500]
on = on.set_index('TIMESTAMP')
cols = list(on.columns)
shut.loc[:, ('Anomaly')] = 'Shutdown'
shut = shut.set_index('TIMESTAMP')

on.describe()

#importing functions for anomaly detection and preprocessing
from pyod.models.abod import ABOD
from pyod.models.auto_encoder import AutoEncoder
from sklearn.decomposition import PCA
from sklearn.preprocessing import RobustScaler

#preprocessing
X_train = on.iloc[:,:]
pca = PCA(n_components = 15)
X_train = pca.fit_transform(X_train)
scale = RobustScaler()
X_train = scale.fit_transform(X_train)

#machine learning model
clf_1 = ABOD(contamination = 0.1, n_neighbors = 100)
clf_1.fit(X_train)
pred_1 = clf_1.predict(X_train)

#output of the ML model
out_1 = []
for i in range(0, len(pred_1)):
  if pred_1[i] == 0:
    out_1.append('Normal')
  else:
    out_1.append('Abnormal')

state_1 = pd.DataFrame(out_1, columns = ['Condition'])
state_1 = state_1.loc[state_1['Condition'] == 'Abnormal'] 
ab_state1 = list(state_1.index.values.tolist())

#Deep Learning model using pyod library
clf_2 = AutoEncoder(hidden_neurons = [15, 64, 32, 64, 15], epochs = 350, 
                    batch_size = 128, preprocessing = False, verbose = 0,
                    random_state = 1234, contamination = 0.1,
                    validation_size = 0.3)
clf_2.fit(X_train)
pred_2 = clf_2.predict(X_train)

#output of the DL model
out_2 = []
for i in range(0, len(pred_2)):
  if pred_2[i] == 0:
    out_2.append('Normal')
  else:
    out_2.append('Abnormal')

state_2 = pd.DataFrame(out_2, columns = ['Condition'])
state_2 = state_2.loc[state_2['Condition'] == 'Abnormal'] 
ab_state2 = list(state_2.index.values.tolist())

#plotting results for three ranges of sensor value and two detectors mentioned above

# range - (0,40), model - ABOD
plt.figure(figsize = [30,10])
columns = ['BFP_2B_IBRD_SEAL_INJ_FLOW_',	'BFP_2B_OBRD_SEAL_INJ_FLOW_', 'AUX_CDSR_2B_PRESS_________', 'BFPT_B_VALVE_DEMAND_HP_STO',	'BFPT_B_VALVE_DEMAND_LP_STO']
X = on[columns]
plt.plot(X)
for xc in ab_state1:
  plt.axvline(x = xc, alpha = 0.05, color = 'yellow')
ax = plt.gca()
ax.axes.xaxis.set_visible(False)
plt.legend(columns)
plt.show()

#range - (0,40), model - Neural Network
plt.figure(figsize = [30,10])
columns = ['BFP_2B_IBRD_SEAL_INJ_FLOW_',	'BFP_2B_OBRD_SEAL_INJ_FLOW_', 'AUX_CDSR_2B_PRESS_________', 'BFPT_B_VALVE_DEMAND_HP_STO',	'BFPT_B_VALVE_DEMAND_LP_STO']
X = on[columns]
plt.plot(X)
for xc in ab_state2:
  plt.axvline(x = xc, alpha = 0.05, color = 'red')
ax = plt.gca()
ax.axes.xaxis.set_visible(False)
plt.legend(columns)
plt.show()

# range - (0,350), model - ABOD
plt.figure(figsize = [30,10])
columns = ['BFP_SUCT_HDR_PRESS________', 'BFP_SUCTION_HDR_TEMP______', '2B_TDBFP_RECIRC_FLOW______', 'BFP_DISCHARGE_HEADER_TEMP_', 'BFP_2B_BARREL_TOP_IBRD_TEM']
X = on[columns]
plt.plot(X)
for xc in ab_state1:
  plt.axvline(x = xc, alpha = 0.05, color = 'yellow')
ax = plt.gca()
ax.axes.xaxis.set_visible(False)
plt.legend(columns)
plt.show()

# range - (0,350), model - Neural Network
plt.figure(figsize = [30,10])
columns = ['BFP_SUCT_HDR_PRESS________', 'BFP_SUCTION_HDR_TEMP______', '2B_TDBFP_RECIRC_FLOW______', 'BFP_DISCHARGE_HEADER_TEMP_', 'BFP_2B_BARREL_TOP_IBRD_TEM']
X = on[columns]
plt.plot(X)
for xc in ab_state2:
  plt.axvline(x = xc, alpha = 0.05, color = 'red')
ax = plt.gca()
ax.axes.xaxis.set_visible(False)
plt.legend(columns)
plt.show()

# range - (0,6000), model - ABOD
plt.figure(figsize = [30,10])
columns = ['BFP_2B_DISCHARGE_FLOW_____', '2B_TDBFP_DISCHARGE_FLOW___', 'BFP_DSCH_HDR_PRESS________', 'BFPT_B_LP_SPEED_INPUT__1__', 'BFPT_B_LP_SPEED_INPUT__2__']
X = on[columns]
plt.plot(X)
for xc in ab_state1:
  plt.axvline(x = xc, alpha = 0.05, color = 'yellow')
ax = plt.gca()
ax.axes.xaxis.set_visible(False)
plt.legend(columns)
plt.show()

# range - (0,6000), model - Neural Network
plt.figure(figsize = [30,10])
columns = ['BFP_2B_DISCHARGE_FLOW_____', '2B_TDBFP_DISCHARGE_FLOW___', 'BFP_DSCH_HDR_PRESS________', 'BFPT_B_LP_SPEED_INPUT__1__', 'BFPT_B_LP_SPEED_INPUT__2__']
X = on[columns]
plt.plot(X)
for xc in ab_state2:
  plt.axvline(x = xc, alpha = 0.05, color = 'red')
ax = plt.gca()
ax.axes.xaxis.set_visible(False)
plt.legend(columns)
plt.show()


#Deep Learning model using TensorFlow

#preprocessing
from sklearn.preprocessing import StandardScaler

X_train = on.iloc[:,:]

scaler = StandardScaler()
scaler = scaler.fit(X_train)

X_train = scaler.transform(X_train)

#creating sequences for RNN
def create_sequences(X, y, time_steps):
  Xs, ys = [], []
  for i in range(len(X) - time_steps):
    Xs.append(X[i:i + time_steps])
    ys.append(y[i:i + time_steps])
  return np.array(Xs), np.array(ys)

#sequence length for RNN
time_steps = 50

#training set for the model
X_train, y_train = create_sequences(X_train, X_train, time_steps)
print(X_train.shape, y_train.shape)

timesteps = X_train.shape[1]
num_features = X_train.shape[2]

#building the auto-encoder decoder model
import tensorflow as tf
tf.random.set_seed(1234)
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, RepeatVector, TimeDistributed

model = Sequential([
                    LSTM(64, input_shape = (timesteps, num_features), activation = 'tanh', return_sequences = True),
                    LSTM(128, activation = 'tanh'),
                    RepeatVector(timesteps),
                    LSTM(128, return_sequences = True, activation = 'tanh'),
                    LSTM(64, return_sequences = True, activation = 'tanh'),
                    TimeDistributed(Dense(num_features, activation = 'tanh'))
])

model.compile(loss = 'mae', optimizer = 'adam')
model.summary()

#training the model on the dataset
es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3, mode = 'min')
history = model.fit(
    X_train, y_train,
    epochs = 50,
    batch_size = 128,
    validation_split = 0.1,
    callbacks = [es],
    shuffle = False
)

#plotting validation loss and training loss 
plt.plot(history.history['loss'], label = 'Training Loss')
plt.plot(history.history['val_loss'], label = 'Validation Loss')
plt.legend()

#predicting the output for X_train 

#calculating loss for each row in the dataset
X_train_pred = model.predict(X_train)
train_mae_loss = np.mean(np.mean(np.abs(X_train_pred - X_train), axis = 1), axis = 1)
train_mae_loss = pd.DataFrame(train_mae_loss, columns = ['Error'])

#calculating loss for each feature in the dataset
mae_loss = np.mean(np.mean(np.abs(X_train_pred - X_train), axis = 1), axis = 0)
mae_loss = pd.DataFrame(mae_loss, columns = ['Error'])
mae_loss.describe()

#selecting threshold for feature loss
threshold = 0.431
mae_loss['Sensor'] = cols
mae_loss['Threshold'] = threshold
mae_loss['Contributing'] = mae_loss.Error > mae_loss.Threshold
mae_loss = mae_loss.set_index('Sensor')
mae_loss

#plotting distribution of loss for all the rows in the dataset
import seaborn as sns
sns.set(style = 'whitegrid', palette = 'muted')
sns.distplot(train_mae_loss, bins = 100, kde = True)

#selecting threshold for anomaly
threshold = 0.75
train_score_df = pd.DataFrame(on[time_steps:])
train_score_df['Loss'] = train_mae_loss['Error'].values
train_score_df['Threshold'] = threshold
train_score_df['Anomaly'] = train_score_df.Loss > train_score_df.Threshold

train_score_df

#number of anomalies
anomaly = train_score_df[train_score_df.Anomaly == True]
ab_list = list(anomaly.index.values.tolist())
len(ab_list)

#plotting the graphs for DL model using TensorFlow

# range - (0,30), model - Recurrent Neural Network
plt.figure(figsize = [30,10])
columns = ['BFP_2B_IBRD_SEAL_INJ_FLOW_',	'BFP_2B_OBRD_SEAL_INJ_FLOW_', 'AUX_CDSR_2B_PRESS_________', 'BFPT_B_VALVE_DEMAND_HP_STO',	'BFPT_B_VALVE_DEMAND_LP_STO']
X = train_score_df[columns]
plt.plot(X)
for xc in ab_list:
  plt.axvline(x = xc, alpha = 0.05, color = 'blue')
ax = plt.gca()
ax.axes.xaxis.set_visible(False)
plt.legend(columns)
plt.show()

# range - (0,350), model - Recurrent Neural Network
plt.figure(figsize = [30,10])
columns = ['BFP_SUCT_HDR_PRESS________', 'BFP_SUCTION_HDR_TEMP______', '2B_TDBFP_RECIRC_FLOW______', 'BFP_DISCHARGE_HEADER_TEMP_', 'BFP_2B_BARREL_TOP_IBRD_TEM']
X = train_score_df[columns]
plt.plot(X)
for xc in ab_list:
  plt.axvline(x = xc, alpha = 0.05, color = 'blue')
ax = plt.gca()
ax.axes.xaxis.set_visible(False)
plt.legend(columns)
plt.show()

# range - (0,6000), model - Recurrent Neural Network
plt.figure(figsize = [30,10])
columns = ['BFP_2B_DISCHARGE_FLOW_____', '2B_TDBFP_DISCHARGE_FLOW___', 'BFP_DSCH_HDR_PRESS________', 'BFPT_B_LP_SPEED_INPUT__1__', 'BFPT_B_LP_SPEED_INPUT__2__']
X = train_score_df[columns]
plt.plot(X)
for xc in ab_list:
  plt.axvline(x = xc, alpha = 0.05, color = 'blue')
ax = plt.gca()
ax.axes.xaxis.set_visible(False)
plt.legend(columns)
plt.show()

#Final output for each timestamp
out = shut.reset_index().merge(train_score_df.reset_index(), how = 'outer')
col = ['TIMESTAMP', 'Anomaly']
out = out[col]
out = out.sort_values(by = 'TIMESTAMP')
out = out.set_index(out['TIMESTAMP'])
out = out.drop(columns = ['TIMESTAMP'])
out

